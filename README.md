# cheat-aiml
Perils of generative AI, language models, ML, and DL. 

Sometimes, while we come across ChatGPT like generative AI implementations, such language models, machine learning, etc. I wonder what have we done actually? what have we learned actually? Philosophy - of why, to do or not to do - is lost in a Ph.D. pushed on staple paper-based thesis. As if tracking user activities and behaviour were not enought, new dangerous weapons are being made by enterprises using data.     

These are probable concerns and perils of such dangerous models:    

* IP Rights for writers    

* Privacy of individuals    

* Plagiarism, esp in academia and journalism    
  - content can be derived purely from existing content and can be presented in such a way to defeat plagiarism detection tools. Such content will be published and citing such content, more stories can be manufactured.     

* Creativity, originality of thinking and writing 
  - when machines can paint, create music, write acrticles, stories and poems, a soul and experience will be missing in such models    

* Misguided truth that is on the internet or in news    
  - unverified content can be plastered in print and digital media, leave researchers and domain experts - how commom people will seek the truth?    

* Ability to modify how we think    
  - colleges have started tinkering labs and avenues to build things from scratch. Why?    
  - when content is available on query like social media feed, it can alter the thought process and suppress "think-ability".   

* Murder of curiosity and inquiry     
  - how curiosity and inquiry for knowledge will survive on campuses?    

* Rational mind, building context, building systems, troubleshooting skils     
  - if lectures and videos/demos are available online, should we close schools and colleges? why?    
  - who will build new content and work on next problems? how will we train individuals to go beyond "what-we-know"?    

* Ability to change the way we raise our kids or infact we create the future    
